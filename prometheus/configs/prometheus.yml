scrape_configs:
  # Make Prometheus scrape itself for metrics.
  - job_name: 'prometheus'
    static_configs:
    - targets: ['192.168.28.9:9090']
   
  - job_name: 'Translator Service'
    metrics_path: translator_translator-service/admin/prometheus
    scrape_interval: 15s
    dns_sd_configs:
      - names: ['tasks.translator_translator-service']
        type: A
        port: 8887
        # The time after which the provided names are refreshed
        [ refresh_interval: <duration> | default = 30s ]
        

  # Create a job for Docker Swarm containers.
  - job_name: 'dockerswarm'
    dockerswarm_sd_configs:
      - host: unix:///var/run/docker.sock
        role: tasks
    relabel_configs:
      # Only keep containers that should be running.
      - source_labels: [__meta_dockerswarm_task_desired_state]
        regex: running
        action: keep
      # Only keep containers that have a `prometheus-job` label.
      - source_labels: [__meta_dockerswarm_service_label_prometheus_job]
        regex: .+
        action: keep
      # Use the prometheus-job Swarm label as Prometheus job label.
      - source_labels: [__meta_dockerswarm_service_label_prometheus_job]
        target_label: job

  - job_name: 'blackbox'
    metrics_path: /probe
    params:
      module: [http_2xx]  # Look for a HTTP 200 response.
    static_configs:
      - targets:
        - https://status.cloud.google.com
        - https://www.githubstatus.com
        - https://status.aws.amazon.com
        - https://azure.microsoft.com/en-us/status
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 192.168.28.9:9115

